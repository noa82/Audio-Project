{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "with all data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DKJM3o0KamD"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('drive/MyDrive/project/wave_data_class_all.csv')\n",
        "\n",
        "lables = pd.read_csv('drive/MyDrive/project/labels_data_class_all.csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaBMh9_VKkHa"
      },
      "source": [
        "class MyModel:\n",
        "    \n",
        "    def __init__(self,data,lables ):  \n",
        "        \n",
        "        self.data = data\n",
        "        self.lables = lables\n",
        "        self.MFCC_data = []\n",
        "        \n",
        "    def train_test(self):\n",
        "        X_train, X_test, lables_train, lables_test = train_test_split(self.data, self.lables, test_size=0.2, random_state=42,stratify=lables['emotion'])\n",
        "        return X_train, X_test, lables_train, lables_test\n",
        "    \n",
        "    def conv_model(self,input_shape1):\n",
        "        \n",
        "        model = tf.keras.Sequential()\n",
        "        \n",
        "        model.add(tf.keras.layers.Conv2D(16,(5,5),strides=(1,1),padding ='same',input_shape=input_shape1))\n",
        "        model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "        \n",
        "        model.add(tf.keras.layers.Conv2D(32,(5,5),strides = (1,1),padding ='same'))\n",
        "        model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "        \n",
        "        model.add(tf.keras.layers.Conv2D(64,(5,5),strides = (1,1),padding ='same'))\n",
        "        model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "        \n",
        "        #model.add(tf.keras.layers.Conv2D(128,(5,5),strides = (1,1),padding ='same'))\n",
        "        #model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "\n",
        "        #model.add(tf.keras.layers.Conv2D(256,(5,5),strides = (1,1),padding ='same'))\n",
        "        #model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "\n",
        "        model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
        "        model.add(tf.keras.layers.Dropout(0))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        \n",
        "        #model.add(tf.keras.layers.Dense(256,activation=tf.keras.activations.relu))\n",
        "        #model.add(tf.keras.layers.Dense(128,activation=tf.keras.activations.relu))\n",
        "        model.add(tf.keras.layers.Dense(64,activation=tf.keras.activations.relu))\n",
        "        model.add(tf.keras.layers.Dense(32,activation=tf.keras.activations.relu))\n",
        "        model.add(tf.keras.layers.Dense(8,activation=tf.keras.activations.softmax))\n",
        "        \n",
        "        model.compile(optimizer= 'adam',loss =tf.keras.losses.CategoricalCrossentropy() ,metrics=(['acc']))\n",
        "        model.summary()\n",
        "        \n",
        "        return model\n",
        "        #shape 415,434,13\n",
        "    \n",
        "    \n",
        "    def recurrent_model(self,input_shape1):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.LSTM(32, return_sequences=True, input_shape = input_shape1))\n",
        "        #model.add(tf.keras.layers.LSTM(64, return_sequences=True))\n",
        "        model.add(tf.keras.layers.Dropout(0.1))\n",
        "        #model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64,activation=tf.keras.activations.relu)))\n",
        "        \n",
        "        #model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32,activation=tf.keras.activations.relu)))\n",
        "        #model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(16,activation=tf.keras.activations.relu)))\n",
        "        model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(8,activation=tf.keras.activations.relu)))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(8,activation=tf.keras.activations.softmax))\n",
        "\n",
        "        model.compile(optimizer= 'adam',loss =tf.keras.losses.CategoricalCrossentropy() ,metrics=(['acc']))\n",
        "\n",
        "        model.summary()\n",
        "        \n",
        "        return model\n",
        "      \n",
        "    def new_conv_model(self,input_shape1):\n",
        "        \n",
        "        model = tf.keras.Sequential()\n",
        "        \n",
        "        model.add(tf.keras.layers.Conv2D(128,(5,5),strides=(1,1),padding ='same',input_shape=input_shape1))\n",
        "        model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "        model.add(tf.keras.layers.Dropout(0.1))\n",
        "        model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(128,(5,5),strides=(1,1),padding ='same'))\n",
        "        model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "        model.add(tf.keras.layers.Dropout(0.1))\n",
        "        #model.add(tf.keras.layers.MaxPool2D((2,2))) \n",
        "\n",
        "        #model.add(tf.keras.layers.Conv2D(32,(5,5),strides = (1,1),padding ='same'))\n",
        "        #model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "        \n",
        "        #model.add(tf.keras.layers.Conv2D(64,(5,5),strides = (1,1),padding ='same'))\n",
        "        #model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "        \n",
        "        #model.add(tf.keras.layers.Conv2D(128,(5,5),strides = (1,1),padding ='same'))\n",
        "        #model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "\n",
        "        #model.add(tf.keras.layers.Conv2D(256,(5,5),strides = (1,1),padding ='same'))\n",
        "        #model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
        "\n",
        "        #model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
        "        #model.add(tf.keras.layers.Dropout(0.5))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        \n",
        "        #model.add(tf.keras.layers.Dense(256,activation=tf.keras.activations.relu))\n",
        "        #model.add(tf.keras.layers.Dense(128,activation=tf.keras.activations.relu))\n",
        "        #model.add(tf.keras.layers.Dense(64,activation=tf.keras.activations.relu))\n",
        "        #model.add(tf.keras.layers.Dense(32,activation=tf.keras.activations.relu))\n",
        "        model.add(tf.keras.layers.Dense(7,activation=tf.keras.activations.softmax))\n",
        "        \n",
        "        model.compile(optimizer= 'adam',loss =tf.keras.losses.CategoricalCrossentropy() ,metrics=(['acc']))\n",
        "        model.summary()\n",
        "        \n",
        "        return model\n",
        "      \n",
        "      # shape 415,434,13\n",
        "    def new_recurrent_model(self,input_shape1):\n",
        "        model = tf.keras.Sequential()\n",
        "\n",
        "        model.add(tf.keras.layers.LSTM(128, return_sequences=True, input_shape = input_shape1))\n",
        "        model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
        "        #model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "        #model.add(tf.keras.layers.Dropout(0.3))\n",
        "        #model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "        model.add(tf.keras.layers.Dropout(0.3))\n",
        "                \n",
        "        model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64,activation=tf.keras.activations.relu)))\n",
        "        model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32,activation=tf.keras.activations.relu)))\n",
        "        model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(16,activation=tf.keras.activations.relu)))\n",
        "\n",
        "        #model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(8,activation=tf.keras.activations.relu)))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(7,activation=tf.keras.activations.softmax))\n",
        "\n",
        "        model.compile(optimizer= 'adam',loss = tf.keras.losses.CategoricalCrossentropy() ,metrics=(['acc']))\n",
        "\n",
        "        model.summary()\n",
        "        \n",
        "        return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OoaFmC5oMU",
        "outputId": "16792658-589e-480f-d2ac-38c8f047788c"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2452, 525)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3EN9NjtKrvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "901ca143-26de-46f9-9a80-dddf0ab5e84a"
      },
      "source": [
        "temp = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(data)):\n",
        "  temp.append((np.array(data.iloc[i,:]).reshape(434,13)))\n",
        "        \n",
        "data = temp\n",
        "data = np.array(data)\n",
        "\n",
        "for i in range(data.shape[1]):\n",
        "  for j in range(data.shape[2]):\n",
        "    data[i][j] = (data[i][j] - np.mean(data[i][j]))/np.std(data[i][j])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e1c184bcd3b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m434\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyZhzONgopoc",
        "outputId": "c6c125d7-935b-4c3b-8515-2225fa03fea5"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2452, 434, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeAb3JgQKuM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "bfd1d2dc-4c7e-4263-b10f-67fd5de58941"
      },
      "source": [
        "model = MyModel(data,lables)\n",
        "\n",
        "\n",
        "X_train, X_test, lables_train, lables_test = model.train_test()\n",
        "    \n",
        "y_train = lables_train.iloc[:,-1]\n",
        "y_train = tf.keras.utils.to_categorical(y_train-1, dtype =\"uint8\") \n",
        "    \n",
        "y_test = lables_test.iloc[:,-1]\n",
        "y_test = tf.keras.utils.to_categorical(y_test-1, dtype =\"uint8\") \n",
        "\n",
        "input_shape = (X_train.shape[1],X_train.shape[2],1)\n",
        "    \n",
        "    \n",
        "    \n",
        "batch_size = 32\n",
        "input_shape = (X_train.shape[1],X_train.shape[2],1)\n",
        "input_shape_rec = (X_train.shape[1],X_train.shape[2])\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6556f034dd53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlables_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlables_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MyModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqMGpig5Kx09",
        "outputId": "f83637e8-12fd-401b-8bf8-7fe2345574a5"
      },
      "source": [
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1961, 434, 13) (491, 434, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kMTJln4Kztx"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
        "\n",
        "X_train_rec = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2])\n",
        "X_test_rec = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2])\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xuP_FsoLH5R"
      },
      "source": [
        "new_X_train = []\n",
        "new_y_train = []\n",
        "for i in range(len(X_train)):\n",
        "    if sum(y_train[i] == [1,0,0,0,0,0,0,0]) != 8:\n",
        "        new_X_train.append(X_train[i])\n",
        "        new_y_train.append(y_train[i])\n",
        "new_X_train = np.array(new_X_train)\n",
        "new_y_train = np.array(new_y_train)[:,1:]       \n",
        "\n",
        "new_X_test = []\n",
        "new_y_test = []\n",
        "for i in range(len(X_test)):\n",
        "    if sum(y_test[i] == [1,0,0,0,0,0,0,0]) != 8:\n",
        "        new_X_test.append(X_test[i])\n",
        "        new_y_test.append(y_test[i])\n",
        "new_X_test = np.array(new_X_test)\n",
        "new_y_test = np.array(new_y_test)[:,1:]   \n",
        "\n",
        "\n",
        "new_X_train_rec = []\n",
        "new_y_train = []\n",
        "for i in range(len(X_train_rec)):\n",
        "    if sum(y_train[i] == [1,0,0,0,0,0,0,0]) != 8:\n",
        "        new_X_train_rec.append(X_train_rec[i])\n",
        "        new_y_train.append(y_train[i])\n",
        "new_X_train_rec = np.array(new_X_train_rec)\n",
        "new_y_train = np.array(new_y_train)[:,1:]  \n",
        "\n",
        "new_X_test_rec = []\n",
        "new_y_test = []\n",
        "for i in range(len(X_test_rec)):\n",
        "    if sum(y_test[i] == [1,0,0,0,0,0,0,0]) != 8:\n",
        "        new_X_test_rec.append(X_test_rec[i])\n",
        "        new_y_test.append(y_test[i])\n",
        "new_X_test_rec = np.array(new_X_test_rec)\n",
        "new_y_test = np.array(new_y_test)[:,1:]   \n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rBMW27eLIbm"
      },
      "source": [
        "new_input_shape = (new_X_train.shape[1],new_X_train.shape[2],1)\n",
        "new_input_shape_rec = (new_X_train.shape[1],new_X_train.shape[2])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z72tnhgaLKkG"
      },
      "source": [
        "**Recurrent Neural Network - LSTM**  \n",
        "without the \"natural\" emotion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VObZZZYLMxO",
        "outputId": "0f97534b-3548-4493-cab0-cd4a8c1dcb9d"
      },
      "source": [
        "new_model_rec = model.new_recurrent_model(new_input_shape_rec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_37 (LSTM)               (None, 434, 128)          72704     \n",
            "_________________________________________________________________\n",
            "lstm_38 (LSTM)               (None, 434, 128)          131584    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 434, 128)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_66 (TimeDis (None, 434, 64)           8256      \n",
            "_________________________________________________________________\n",
            "time_distributed_67 (TimeDis (None, 434, 32)           2080      \n",
            "_________________________________________________________________\n",
            "time_distributed_68 (TimeDis (None, 434, 16)           528       \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 6944)              0         \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 7)                 48615     \n",
            "=================================================================\n",
            "Total params: 263,767\n",
            "Trainable params: 263,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jakeZG-CLOfy",
        "outputId": "f6d59741-7771-4145-ee01-45f32c25a929"
      },
      "source": [
        "new_model_rec.fit(new_X_train_rec,new_y_train,epochs=2000,batch_size = 200,shuffle = True,validation_data=(new_X_test_rec,new_y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 4s 170ms/step - loss: 1.8851 - acc: 0.1883 - val_loss: 1.7289 - val_acc: 0.2892\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 1.6067 - acc: 0.3386 - val_loss: 1.4862 - val_acc: 0.3929\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3991 - acc: 0.4479 - val_loss: 1.3901 - val_acc: 0.4283\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.2233 - acc: 0.5238 - val_loss: 1.4650 - val_acc: 0.4393\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.1444 - acc: 0.5551 - val_loss: 1.2947 - val_acc: 0.5011\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 1.0445 - acc: 0.5851 - val_loss: 1.2306 - val_acc: 0.5210\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.9090 - acc: 0.6275 - val_loss: 1.3125 - val_acc: 0.5276\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.8332 - acc: 0.7000 - val_loss: 1.0577 - val_acc: 0.5740\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.6596 - acc: 0.7756 - val_loss: 1.0291 - val_acc: 0.6071\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.5660 - acc: 0.7911 - val_loss: 1.1759 - val_acc: 0.6026\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.4918 - acc: 0.8130 - val_loss: 1.2728 - val_acc: 0.5673\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.4443 - acc: 0.8351 - val_loss: 1.2094 - val_acc: 0.5938\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.3432 - acc: 0.8758 - val_loss: 1.2239 - val_acc: 0.6181\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.3346 - acc: 0.8858 - val_loss: 1.2728 - val_acc: 0.6004\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2526 - acc: 0.9093 - val_loss: 1.1943 - val_acc: 0.6380\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.1737 - acc: 0.9436 - val_loss: 1.3814 - val_acc: 0.6269\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.1418 - acc: 0.9558 - val_loss: 1.3558 - val_acc: 0.6313\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.1301 - acc: 0.9613 - val_loss: 1.4399 - val_acc: 0.6358\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.1284 - acc: 0.9591 - val_loss: 1.6270 - val_acc: 0.6159\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0995 - acc: 0.9715 - val_loss: 1.3686 - val_acc: 0.6623\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0599 - acc: 0.9854 - val_loss: 1.6552 - val_acc: 0.6402\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0380 - acc: 0.9884 - val_loss: 1.6162 - val_acc: 0.6490\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0297 - acc: 0.9946 - val_loss: 1.6267 - val_acc: 0.6490\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.0243 - acc: 0.9951 - val_loss: 1.7225 - val_acc: 0.6600\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0183 - acc: 0.9954 - val_loss: 1.8414 - val_acc: 0.6600\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0184 - acc: 0.9941 - val_loss: 1.7901 - val_acc: 0.6799\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0122 - acc: 0.9956 - val_loss: 1.8640 - val_acc: 0.6777\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0118 - acc: 0.9947 - val_loss: 1.9027 - val_acc: 0.6733\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0120 - acc: 0.9949 - val_loss: 1.9845 - val_acc: 0.6843\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0101 - acc: 0.9958 - val_loss: 2.0184 - val_acc: 0.6711\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 2.0389 - val_acc: 0.6865\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0078 - acc: 0.9960 - val_loss: 2.0726 - val_acc: 0.6821\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0085 - acc: 0.9963 - val_loss: 2.1146 - val_acc: 0.6799\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0066 - acc: 0.9973 - val_loss: 2.2486 - val_acc: 0.6755\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 2.1730 - val_acc: 0.6733\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0057 - acc: 0.9971 - val_loss: 2.2149 - val_acc: 0.6777\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 2.2875 - val_acc: 0.6689\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0083 - acc: 0.9966 - val_loss: 2.2456 - val_acc: 0.6623\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 2.2380 - val_acc: 0.6623\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.0100 - acc: 0.9952 - val_loss: 2.2956 - val_acc: 0.6733\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 2.3594 - val_acc: 0.6645\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0051 - acc: 0.9979 - val_loss: 2.3766 - val_acc: 0.6689\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0055 - acc: 0.9972 - val_loss: 2.3980 - val_acc: 0.6689\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.0050 - acc: 0.9984 - val_loss: 2.4324 - val_acc: 0.6623\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0057 - acc: 0.9969 - val_loss: 2.4561 - val_acc: 0.6645\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.0041 - acc: 0.9978 - val_loss: 2.4745 - val_acc: 0.6711\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 0.0031 - acc: 0.9980 - val_loss: 2.4948 - val_acc: 0.6689\n",
            "Epoch 48/2000\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0056 - acc: 0.9969"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-873518f97914>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_train_rec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_test_rec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHFD_NAdLQl7",
        "outputId": "27513d29-5db9-4227-f2a4-ade0c009e05d"
      },
      "source": [
        "y_pred = new_model_rec.predict(new_X_test_rec)\n",
        "y_pred_raw = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    \n",
        "y_test_raw = np.argmax(new_y_test, axis=1)\n",
        "    \n",
        "print(\"test accuracy: \",sum(y_pred_raw == y_test_raw)/len(y_test_raw))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfNzVRq7LSv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb8637a-cc3b-42f5-8c66-a3eb60b29445"
      },
      "source": [
        "new_good = {0:0,1:0,2:0,3:0,4:0,5:0,6:0}\n",
        "\n",
        "for i in range(len(y_pred_raw)):\n",
        "  if y_pred_raw[i]==y_test_raw[i]:\n",
        "    new_good[y_pred_raw[i]] += 1\n",
        "  \n",
        "vals,freq = np.unique(y_test_raw,return_counts=True)\n",
        "\n",
        "print(new_good)\n",
        "\n",
        "real = {0:0,1:0,2:0,3:0,4:0,5:0,6:0}\n",
        "\n",
        "for i in range(len(freq)):\n",
        "  real[i] = freq[i]\n",
        "\n",
        "print(real)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "new_emotions = { 0 : 'calm', 1 : 'happy', 2 : 'sad', 3 : 'angry', 4 : 'fearful', 5 : 'disgust', 6 : 'surprised'}\n",
        "    \n",
        "acc = {}\n",
        "for i in range(len(new_good)):\n",
        "  acc[new_emotions[i]] = new_good[i]/real[i]\n",
        "\n",
        "print('accuracy per feeling: ', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 48, 1: 54, 2: 51, 3: 62, 4: 48, 5: 20, 6: 19}\n",
            "{0: 75, 1: 75, 2: 75, 3: 75, 4: 75, 5: 39, 6: 39}\n",
            "accuracy per feeling:  {'calm': 0.64, 'happy': 0.72, 'sad': 0.68, 'angry': 0.8266666666666667, 'fearful': 0.64, 'disgust': 0.5128205128205128, 'surprised': 0.48717948717948717}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXMjK6nDLZKh"
      },
      "source": [
        "**Convolutional Neural Network**  \n",
        "without the \"natural\" feeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxlrtgMJLbzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3998b5-561b-4cac-e264-1ef172a396e9"
      },
      "source": [
        "new_model1conv = model.new_conv_model(new_input_shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 434, 13, 128)      3328      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 434, 13, 128)      0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 434, 13, 128)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 217, 6, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 217, 6, 128)       409728    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 217, 6, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 217, 6, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 166656)            0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 7)                 1166599   \n",
            "=================================================================\n",
            "Total params: 1,579,655\n",
            "Trainable params: 1,579,655\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AWhMwe1LcVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "550cea6e-2403-474f-f4eb-197c98263088"
      },
      "source": [
        "new_model1conv.fit(new_X_train,new_y_train,epochs=100,batch_size = 50,shuffle = True,validation_data=(new_X_test,new_y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "37/37 [==============================] - 3s 57ms/step - loss: 10.6299 - acc: 0.1967 - val_loss: 1.7184 - val_acc: 0.2958\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 1.5680 - acc: 0.3793 - val_loss: 1.5659 - val_acc: 0.3885\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 1.3696 - acc: 0.4628 - val_loss: 1.5673 - val_acc: 0.3907\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 1.1993 - acc: 0.5469 - val_loss: 1.5604 - val_acc: 0.4084\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 1.0923 - acc: 0.5835 - val_loss: 1.6040 - val_acc: 0.3996\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.9650 - acc: 0.6283 - val_loss: 1.6104 - val_acc: 0.4525\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.8368 - acc: 0.6865 - val_loss: 1.8529 - val_acc: 0.3687\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.7532 - acc: 0.7199 - val_loss: 1.8859 - val_acc: 0.4194\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.6584 - acc: 0.7551 - val_loss: 1.8957 - val_acc: 0.3951\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.6030 - acc: 0.7807 - val_loss: 2.1798 - val_acc: 0.4150\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.4832 - acc: 0.8248 - val_loss: 2.3995 - val_acc: 0.4040\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.4330 - acc: 0.8356 - val_loss: 2.4198 - val_acc: 0.4260\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.4164 - acc: 0.8590 - val_loss: 2.5767 - val_acc: 0.4172\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.3497 - acc: 0.8781 - val_loss: 2.6314 - val_acc: 0.4349\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.3307 - acc: 0.8820 - val_loss: 2.9824 - val_acc: 0.4172\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 2s 56ms/step - loss: 0.2963 - acc: 0.8929 - val_loss: 3.1779 - val_acc: 0.4216\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.2369 - acc: 0.9116 - val_loss: 3.1337 - val_acc: 0.3974\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 2s 54ms/step - loss: 0.2767 - acc: 0.9063 - val_loss: 3.1322 - val_acc: 0.3731\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.3022 - acc: 0.9008 - val_loss: 3.5893 - val_acc: 0.4437\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.2413 - acc: 0.9156 - val_loss: 3.9683 - val_acc: 0.4084\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.3331 - acc: 0.8831 - val_loss: 3.7652 - val_acc: 0.4150\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.2341 - acc: 0.9141 - val_loss: 3.6000 - val_acc: 0.3951\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1720 - acc: 0.9411 - val_loss: 3.9108 - val_acc: 0.4283\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1647 - acc: 0.9413 - val_loss: 4.3571 - val_acc: 0.4084\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1757 - acc: 0.9313 - val_loss: 4.1748 - val_acc: 0.3974\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.2399 - acc: 0.9183 - val_loss: 3.8754 - val_acc: 0.3951\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.3040 - acc: 0.8956 - val_loss: 3.7835 - val_acc: 0.3929\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1950 - acc: 0.9354 - val_loss: 4.3870 - val_acc: 0.4084\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1662 - acc: 0.9444 - val_loss: 4.1925 - val_acc: 0.4150\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1440 - acc: 0.9528 - val_loss: 4.4117 - val_acc: 0.4062\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1348 - acc: 0.9560 - val_loss: 4.7458 - val_acc: 0.4018\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1135 - acc: 0.9616 - val_loss: 4.7419 - val_acc: 0.4018\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1221 - acc: 0.9569 - val_loss: 4.8603 - val_acc: 0.3929\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1331 - acc: 0.9607 - val_loss: 4.7379 - val_acc: 0.4018\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1316 - acc: 0.9582 - val_loss: 5.1199 - val_acc: 0.4172\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1068 - acc: 0.9647 - val_loss: 5.1990 - val_acc: 0.3996\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1058 - acc: 0.9618 - val_loss: 5.6495 - val_acc: 0.4062\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1063 - acc: 0.9606 - val_loss: 5.0274 - val_acc: 0.4172\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1337 - acc: 0.9641 - val_loss: 5.1526 - val_acc: 0.4018\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1794 - acc: 0.9386 - val_loss: 4.6303 - val_acc: 0.4128\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1399 - acc: 0.9564 - val_loss: 5.2590 - val_acc: 0.4305\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1948 - acc: 0.9419 - val_loss: 5.2473 - val_acc: 0.3907\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.2106 - acc: 0.9370 - val_loss: 5.1855 - val_acc: 0.4084\n",
            "Epoch 44/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1385 - acc: 0.9512 - val_loss: 5.1388 - val_acc: 0.4084\n",
            "Epoch 45/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1151 - acc: 0.9669 - val_loss: 5.7202 - val_acc: 0.4172\n",
            "Epoch 46/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0670 - acc: 0.9782 - val_loss: 5.6958 - val_acc: 0.3885\n",
            "Epoch 47/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0973 - acc: 0.9609 - val_loss: 6.0379 - val_acc: 0.3996\n",
            "Epoch 48/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1067 - acc: 0.9609 - val_loss: 6.0054 - val_acc: 0.4084\n",
            "Epoch 49/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0790 - acc: 0.9705 - val_loss: 6.0989 - val_acc: 0.4062\n",
            "Epoch 50/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0666 - acc: 0.9798 - val_loss: 6.6018 - val_acc: 0.3996\n",
            "Epoch 51/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0649 - acc: 0.9726 - val_loss: 5.7512 - val_acc: 0.4150\n",
            "Epoch 52/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0613 - acc: 0.9794 - val_loss: 5.9337 - val_acc: 0.4150\n",
            "Epoch 53/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0638 - acc: 0.9765 - val_loss: 6.1606 - val_acc: 0.3974\n",
            "Epoch 54/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0559 - acc: 0.9847 - val_loss: 5.6412 - val_acc: 0.3841\n",
            "Epoch 55/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.2969 - acc: 0.9102 - val_loss: 6.0895 - val_acc: 0.4150\n",
            "Epoch 56/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1070 - acc: 0.9671 - val_loss: 5.4183 - val_acc: 0.4128\n",
            "Epoch 57/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0757 - acc: 0.9758 - val_loss: 5.4046 - val_acc: 0.4150\n",
            "Epoch 58/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0898 - acc: 0.9726 - val_loss: 6.0476 - val_acc: 0.3929\n",
            "Epoch 59/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0795 - acc: 0.9767 - val_loss: 6.5223 - val_acc: 0.3951\n",
            "Epoch 60/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0651 - acc: 0.9723 - val_loss: 6.1540 - val_acc: 0.4084\n",
            "Epoch 61/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0903 - acc: 0.9699 - val_loss: 6.9910 - val_acc: 0.4150\n",
            "Epoch 62/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0735 - acc: 0.9767 - val_loss: 6.8351 - val_acc: 0.4106\n",
            "Epoch 63/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0622 - acc: 0.9794 - val_loss: 6.8134 - val_acc: 0.4172\n",
            "Epoch 64/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0601 - acc: 0.9785 - val_loss: 7.6239 - val_acc: 0.4062\n",
            "Epoch 65/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0741 - acc: 0.9804 - val_loss: 6.4761 - val_acc: 0.4128\n",
            "Epoch 66/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0868 - acc: 0.9677 - val_loss: 7.0107 - val_acc: 0.3863\n",
            "Epoch 67/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0962 - acc: 0.9693 - val_loss: 6.3328 - val_acc: 0.3885\n",
            "Epoch 68/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0744 - acc: 0.9710 - val_loss: 7.5718 - val_acc: 0.3797\n",
            "Epoch 69/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1068 - acc: 0.9645 - val_loss: 6.9201 - val_acc: 0.3929\n",
            "Epoch 70/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1159 - acc: 0.9645 - val_loss: 6.8998 - val_acc: 0.4018\n",
            "Epoch 71/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1235 - acc: 0.9595 - val_loss: 6.3705 - val_acc: 0.4018\n",
            "Epoch 72/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1308 - acc: 0.9599 - val_loss: 6.6063 - val_acc: 0.4018\n",
            "Epoch 73/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1284 - acc: 0.9656 - val_loss: 7.2760 - val_acc: 0.4040\n",
            "Epoch 74/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0469 - acc: 0.9864 - val_loss: 7.4802 - val_acc: 0.3974\n",
            "Epoch 75/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0677 - acc: 0.9807 - val_loss: 7.0820 - val_acc: 0.4128\n",
            "Epoch 76/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1231 - acc: 0.9596 - val_loss: 7.4228 - val_acc: 0.3885\n",
            "Epoch 77/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0726 - acc: 0.9689 - val_loss: 8.0545 - val_acc: 0.3863\n",
            "Epoch 78/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.1357 - acc: 0.9588 - val_loss: 7.2314 - val_acc: 0.3819\n",
            "Epoch 79/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0632 - acc: 0.9761 - val_loss: 7.1260 - val_acc: 0.3885\n",
            "Epoch 80/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0617 - acc: 0.9783 - val_loss: 7.6469 - val_acc: 0.3841\n",
            "Epoch 81/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0868 - acc: 0.9674 - val_loss: 7.9254 - val_acc: 0.3907\n",
            "Epoch 82/100\n",
            "37/37 [==============================] - 2s 56ms/step - loss: 0.0980 - acc: 0.9731 - val_loss: 7.1652 - val_acc: 0.3974\n",
            "Epoch 83/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0531 - acc: 0.9806 - val_loss: 7.3650 - val_acc: 0.4040\n",
            "Epoch 84/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0754 - acc: 0.9742 - val_loss: 6.7920 - val_acc: 0.3841\n",
            "Epoch 85/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0911 - acc: 0.9718 - val_loss: 8.5496 - val_acc: 0.4084\n",
            "Epoch 86/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0740 - acc: 0.9747 - val_loss: 7.8402 - val_acc: 0.3885\n",
            "Epoch 87/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1102 - acc: 0.9669 - val_loss: 8.0622 - val_acc: 0.4018\n",
            "Epoch 88/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0422 - acc: 0.9824 - val_loss: 7.8325 - val_acc: 0.3885\n",
            "Epoch 89/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0628 - acc: 0.9814 - val_loss: 8.5964 - val_acc: 0.3841\n",
            "Epoch 90/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.1064 - acc: 0.9720 - val_loss: 8.0596 - val_acc: 0.3797\n",
            "Epoch 91/100\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.0731 - acc: 0.9747 - val_loss: 8.8730 - val_acc: 0.3709\n",
            "Epoch 92/100\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 0.0783 - acc: 0.9744 - val_loss: 9.0917 - val_acc: 0.3841\n",
            "Epoch 93/100\n",
            "37/37 [==============================] - 2s 54ms/step - loss: 0.0679 - acc: 0.9747 - val_loss: 8.4792 - val_acc: 0.3863\n",
            "Epoch 94/100\n",
            " 2/37 [>.............................] - ETA: 1s - loss: 0.0096 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-099a54b6dca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model1conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQPy-PKLe4r"
      },
      "source": [
        "y_pred = new_model1conv.predict(new_X_test)\n",
        "y_pred_raw = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    \n",
        "y_test_raw = np.argmax(new_y_test, axis=1)\n",
        "    \n",
        "print(\"test accuracy: \",sum(y_pred_raw == y_test_raw)/len(y_test_raw))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx8VE6MfLhCU"
      },
      "source": [
        "new_good = {0:0,1:0,2:0,3:0,4:0,5:0,6:0}\n",
        "\n",
        "for i in range(len(y_pred_raw)):\n",
        "  if y_pred_raw[i]==y_test_raw[i]:\n",
        "    new_good[y_pred_raw[i]] += 1\n",
        "  \n",
        "vals,freq = np.unique(y_test_raw,return_counts=True)\n",
        "\n",
        "print(new_good)\n",
        "\n",
        "real = {0:0,1:0,2:0,3:0,4:0,5:0,6:0}\n",
        "\n",
        "for i in range(len(freq)):\n",
        "  real[i] = freq[i]\n",
        "\n",
        "print(real)\n",
        "\n",
        "\n",
        "\n",
        "new_emotions = { 0 : 'calm', 1 : 'happy', 2 : 'sad', 3 : 'angry', 4 : 'fearful', 5 : 'disgust', 6 : 'surprised'}\n",
        "    \n",
        "acc = {}\n",
        "for i in range(len(new_good)):\n",
        "  acc[new_emotions[i]] = new_good[i]/real[i]\n",
        "\n",
        "print('accuracy per feeling: ' acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9oT3YVKLnt7"
      },
      "source": [
        "**Recurrent Neural Network - LSTM**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DecfBO0LoH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47542526-86ed-440c-feb0-66ac6427a0d1"
      },
      "source": [
        "model_rec = model.recurrent_model(input_shape_rec)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 434, 32)           5888      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 434, 32)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_21 (TimeDis (None, 434, 8)            264       \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 3472)              0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 8)                 27784     \n",
            "=================================================================\n",
            "Total params: 33,936\n",
            "Trainable params: 33,936\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N_koASPLp1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adfbcd8-ea3e-4d10-a0db-750717d06500"
      },
      "source": [
        "model_rec.fit(X_train_rec,y_train,epochs=100,batch_size = 30,shuffle = True,validation_data=(X_test_rec,y_test))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "66/66 [==============================] - 3s 24ms/step - loss: 1.9850 - acc: 0.2185 - val_loss: 1.6982 - val_acc: 0.3422\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 1.5137 - acc: 0.4383 - val_loss: 1.5533 - val_acc: 0.4012\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 1.3118 - acc: 0.5103 - val_loss: 1.4766 - val_acc: 0.4501\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 1.0923 - acc: 0.6183 - val_loss: 1.4545 - val_acc: 0.4582\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.9763 - acc: 0.6654 - val_loss: 1.4259 - val_acc: 0.4460\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.8376 - acc: 0.7109 - val_loss: 1.4144 - val_acc: 0.4969\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.7216 - acc: 0.7640 - val_loss: 1.4859 - val_acc: 0.4705\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.6490 - acc: 0.7892 - val_loss: 1.4771 - val_acc: 0.4908\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.5585 - acc: 0.8362 - val_loss: 1.4931 - val_acc: 0.4725\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.4907 - acc: 0.8479 - val_loss: 1.5018 - val_acc: 0.4888\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.4289 - acc: 0.8792 - val_loss: 1.5865 - val_acc: 0.4908\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.4013 - acc: 0.8837 - val_loss: 1.6032 - val_acc: 0.4684\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.3308 - acc: 0.9073 - val_loss: 1.6243 - val_acc: 0.4888\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.2840 - acc: 0.9279 - val_loss: 1.6297 - val_acc: 0.5071\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.2601 - acc: 0.9413 - val_loss: 1.7855 - val_acc: 0.4766\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.2491 - acc: 0.9391 - val_loss: 1.7273 - val_acc: 0.5112\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.1861 - acc: 0.9697 - val_loss: 1.7888 - val_acc: 0.4949\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.1967 - acc: 0.9609 - val_loss: 1.8178 - val_acc: 0.5051\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.1863 - acc: 0.9549 - val_loss: 1.8976 - val_acc: 0.4868\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.1590 - acc: 0.9644 - val_loss: 1.8723 - val_acc: 0.4908\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.1389 - acc: 0.9719 - val_loss: 1.9447 - val_acc: 0.4786\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.1298 - acc: 0.9734 - val_loss: 1.9956 - val_acc: 0.5071\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0985 - acc: 0.9854 - val_loss: 1.9644 - val_acc: 0.4908\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0992 - acc: 0.9872 - val_loss: 2.0500 - val_acc: 0.4766\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.1002 - acc: 0.9837 - val_loss: 2.1242 - val_acc: 0.4929\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0930 - acc: 0.9777 - val_loss: 2.1119 - val_acc: 0.4888\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0840 - acc: 0.9803 - val_loss: 2.2032 - val_acc: 0.4786\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0939 - acc: 0.9848 - val_loss: 2.1711 - val_acc: 0.4888\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0699 - acc: 0.9889 - val_loss: 2.2795 - val_acc: 0.4888\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0723 - acc: 0.9886 - val_loss: 2.2729 - val_acc: 0.4827\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0602 - acc: 0.9909 - val_loss: 2.2985 - val_acc: 0.4868\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0643 - acc: 0.9886 - val_loss: 2.3193 - val_acc: 0.4990\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0532 - acc: 0.9886 - val_loss: 2.4332 - val_acc: 0.4908\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0536 - acc: 0.9904 - val_loss: 2.4054 - val_acc: 0.4807\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0472 - acc: 0.9919 - val_loss: 2.3324 - val_acc: 0.4888\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0357 - acc: 0.9970 - val_loss: 2.4329 - val_acc: 0.4827\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 0.0336 - acc: 0.9971 - val_loss: 2.4582 - val_acc: 0.4969\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.0346 - acc: 0.9961 - val_loss: 2.4885 - val_acc: 0.4908\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0312 - acc: 0.9969 - val_loss: 2.4315 - val_acc: 0.4888\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0273 - acc: 0.9971 - val_loss: 2.4905 - val_acc: 0.4888\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0407 - acc: 0.9921 - val_loss: 2.4947 - val_acc: 0.5051\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0544 - acc: 0.9842 - val_loss: 2.4927 - val_acc: 0.4847\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0438 - acc: 0.9916 - val_loss: 2.5327 - val_acc: 0.4888\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0401 - acc: 0.9905 - val_loss: 2.5691 - val_acc: 0.4888\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.0345 - acc: 0.9941 - val_loss: 2.5953 - val_acc: 0.5051\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0328 - acc: 0.9925 - val_loss: 2.5709 - val_acc: 0.4888\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0250 - acc: 0.9960 - val_loss: 2.6057 - val_acc: 0.4847\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0318 - acc: 0.9928 - val_loss: 2.6490 - val_acc: 0.5214\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0554 - acc: 0.9826 - val_loss: 2.7229 - val_acc: 0.5092\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0571 - acc: 0.9824 - val_loss: 2.7233 - val_acc: 0.4949\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0700 - acc: 0.9769 - val_loss: 2.7981 - val_acc: 0.4868\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0912 - acc: 0.9729 - val_loss: 2.7970 - val_acc: 0.4562\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.1133 - acc: 0.9645 - val_loss: 2.8841 - val_acc: 0.4807\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0824 - acc: 0.9691 - val_loss: 2.7526 - val_acc: 0.5153\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0600 - acc: 0.9844 - val_loss: 2.9036 - val_acc: 0.5112\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0508 - acc: 0.9852 - val_loss: 2.9468 - val_acc: 0.4684\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0500 - acc: 0.9831 - val_loss: 2.8752 - val_acc: 0.4929\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0367 - acc: 0.9907 - val_loss: 2.9132 - val_acc: 0.4990\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0456 - acc: 0.9912 - val_loss: 2.9429 - val_acc: 0.4684\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0342 - acc: 0.9937 - val_loss: 3.0178 - val_acc: 0.4949\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0292 - acc: 0.9925 - val_loss: 2.9127 - val_acc: 0.4725\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0174 - acc: 0.9944 - val_loss: 2.8820 - val_acc: 0.5071\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0238 - acc: 0.9940 - val_loss: 2.9293 - val_acc: 0.4929\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0230 - acc: 0.9968 - val_loss: 2.9157 - val_acc: 0.5010\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0156 - acc: 0.9958 - val_loss: 2.9074 - val_acc: 0.4990\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0178 - acc: 0.9957 - val_loss: 2.9629 - val_acc: 0.4929\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0131 - acc: 0.9970 - val_loss: 3.0062 - val_acc: 0.4888\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0107 - acc: 0.9990 - val_loss: 3.0008 - val_acc: 0.4908\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0099 - acc: 0.9983 - val_loss: 3.0795 - val_acc: 0.5031\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0135 - acc: 0.9930 - val_loss: 2.9718 - val_acc: 0.5071\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 3.0228 - val_acc: 0.5051\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0129 - acc: 0.9952 - val_loss: 3.1260 - val_acc: 0.4949\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0084 - acc: 0.9993 - val_loss: 3.0646 - val_acc: 0.4990\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0099 - acc: 0.9949 - val_loss: 3.0793 - val_acc: 0.4949\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0105 - acc: 0.9983 - val_loss: 3.0790 - val_acc: 0.5010\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0111 - acc: 0.9970 - val_loss: 3.1088 - val_acc: 0.5031\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0100 - acc: 0.9978 - val_loss: 3.2004 - val_acc: 0.4847\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0189 - acc: 0.9954 - val_loss: 3.0902 - val_acc: 0.5153\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0108 - acc: 0.9970 - val_loss: 3.2338 - val_acc: 0.5071\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0876 - acc: 0.9640 - val_loss: 3.3873 - val_acc: 0.4888\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.3540 - acc: 0.8886 - val_loss: 3.0785 - val_acc: 0.4725\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.2013 - acc: 0.9321 - val_loss: 3.3021 - val_acc: 0.4644\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.1669 - acc: 0.9342 - val_loss: 2.8844 - val_acc: 0.4847\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0845 - acc: 0.9705 - val_loss: 3.0237 - val_acc: 0.4847\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0533 - acc: 0.9831 - val_loss: 2.8356 - val_acc: 0.5092\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.0184 - acc: 0.9958 - val_loss: 2.9335 - val_acc: 0.4949\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0158 - acc: 0.9967 - val_loss: 2.8967 - val_acc: 0.5031\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.0128 - acc: 0.9972 - val_loss: 2.9252 - val_acc: 0.5071\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 0.0115 - acc: 0.9969 - val_loss: 2.9483 - val_acc: 0.5193\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0139 - acc: 0.9941 - val_loss: 3.0432 - val_acc: 0.5092\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0150 - acc: 0.9979 - val_loss: 3.0061 - val_acc: 0.5010\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0085 - acc: 0.9994 - val_loss: 2.9559 - val_acc: 0.5295\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.0087 - acc: 0.9993 - val_loss: 3.0107 - val_acc: 0.5092\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0094 - acc: 0.9990 - val_loss: 3.0269 - val_acc: 0.5173\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 3.1601 - val_acc: 0.4990\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0199 - acc: 0.9954 - val_loss: 3.0073 - val_acc: 0.5255\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0135 - acc: 0.9935 - val_loss: 3.0230 - val_acc: 0.5275\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0090 - acc: 0.9981 - val_loss: 3.0875 - val_acc: 0.5255\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0096 - acc: 0.9962 - val_loss: 3.0326 - val_acc: 0.5193\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 0.0088 - acc: 0.9960 - val_loss: 3.0597 - val_acc: 0.5356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f52493d45f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_y3Aw5GLsgD"
      },
      "source": [
        "y_pred = model_rec.predict(X_test_rec)\n",
        "y_pred_raw = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    \n",
        "y_test_raw = np.argmax(y_test, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBTtkKFRLs5J"
      },
      "source": [
        "good = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0}\n",
        "\n",
        "for i in range(len(y_pred_raw)):\n",
        "  if y_pred_raw[i]==y_test_raw[i]:\n",
        "    good[y_pred_raw[i]] += 1\n",
        "  \n",
        "vals,freq = np.unique(y_test_raw,return_counts=True)\n",
        "\n",
        "print(good)\n",
        "\n",
        "real = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0}\n",
        "\n",
        "for i in range(len(freq)):\n",
        "  real[i] = freq[i]\n",
        "\n",
        "print(real)\n",
        "\n",
        "\n",
        "\n",
        "emotions = {0 : 'neutral', 1 : 'calm', 2 : 'happy', 3 : 'sad',4 : 'angry', 5 : 'fearful', 6 : 'disgust', 7 : 'surprised'}\n",
        "           \n",
        "acc = {}\n",
        "for i in range(len(good)):\n",
        "  acc[emotions[i]] = good[i]/real[i]\n",
        "\n",
        "print('accuracy per feeling: ' acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33GT_4CoLx_i"
      },
      "source": [
        "**Convolutional Neural Network**  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrCKrbwfL0Pe"
      },
      "source": [
        "model1conv = model.conv_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1ZBvDH5L2Mr"
      },
      "source": [
        "model1conv.fit(X_train,y_train,epochs=100,batch_size = 100,shuffle = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dPJnO6CL4Hv"
      },
      "source": [
        "y_pred = model1conv.predict(X_test)\n",
        "y_pred_raw = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    \n",
        "y_test_raw = np.argmax(y_test, axis=1)\n",
        "    \n",
        "print(\"test accuracy: \",sum(y_pred_raw == y_test_raw)/len(y_test_raw))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVtG2GPwL7St"
      },
      "source": [
        "good = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0}\n",
        "\n",
        "for i in range(len(y_pred_raw)):\n",
        "  if y_pred_raw[i]==y_test_raw[i]:\n",
        "    good[y_pred_raw[i]] += 1\n",
        "  \n",
        "vals,freq = np.unique(y_test_raw,return_counts=True)\n",
        "\n",
        "print(good)\n",
        "\n",
        "real = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0}\n",
        "\n",
        "for i in range(len(freq)):\n",
        "  real[i] = freq[i]\n",
        "\n",
        "print(real)\n",
        "\n",
        "\n",
        "\n",
        "emotions = {0 : 'neutral', 1 : 'calm', 2 : 'happy', 3 : 'sad',4 : 'angry', 5 : 'fearful', 6 : 'disgust', 7 : 'surprised'}\n",
        "           \n",
        "acc = {}\n",
        "for i in range(len(good)):\n",
        "  acc[emotions[i]] = good[i]/real[i]\n",
        "\n",
        "print('accuracy per feeling: ' acc)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}